Week 5-6:
接着前两周的ACL弄，并且进行了presentation。总算把这个东西弄好了。然后

就是进行核心文档算法的开垦, 也就是之前学习算法变种，创新，以及实现性

能数据的对比，代码实现的复杂度相当大，仅仅ACLip技术研究部 算法就直接

突破5000行。

这两周学习了一个 bloom filter，一个linux kernel中采用的 RCU(read-

copy-update)锁机制。
bloom filter就是利用多个hash和bitmap进行非常高效的判定当前数据库中是

否含有这个元素,略微牺牲了精度，但是很好的权衡了时间和空间这么一个矛盾

的问题，实际应用很广泛。这是一个FP,TN的操作，也就是假阳性。这里意思就

是过滤器如果说在数据库中，实际不一定在，但是如果说不在数据库中，那就

肯定不在。至于FP,TN后面会补充。导致这个问题主要原因就是来自于哈希碰撞

，所以精度的损失就是来自于哈希的碰撞(collisions)。
如需要判断一个元素是不是在一个集合中，我们通常做法是把所有元素保存下

来，然后通过比较知道它是不是在集合内，链表、树都是基于这种思路，当集

合内元素个数的变大，我们需要的空间和时间都线性变大，检索速度也越来越

慢。 Bloom filter 采用的是哈希函数的方法，将一个元素映射到一个 m 长度

的阵列上的一个点，当这个点是 1 时，那么这个元素在集合内，反之则不在集

合内。这个方法的缺点就是当检测的元素很多的时候可能有冲突，解决方法就

是使用 k 个哈希 函数对应 k 个点，如果所有点都是 1 的话，那么元素在集

合内，如果有 0 的话，元素则不在集合内。
TP(true positive): 表示正确的判断样本为正
TN(true negative): 表示正确的判断样本为负
FP(false positive): 表示错误的把样本判断成正 (也就是 误报
FN(false negative): 表示错误的把样本判断为负 (也就是 漏报
这个说法是起源于医疗军事，现在多应用于统计。
平时我们所说的精确率(precision)和召回率(recall)可以这么表示:
precision = TP/(TP+FP) //有可能会导致FN变高
recall = TP/(TP+FN)	//有可能会导致FP变高
用于平衡这两个参考数据的一个方程是F1 score(当然这个都是顺藤摸瓜满足好

奇心额外学的)
F=2*recall*precision/(recall + precision)
其实就是 1/F = 1/2(1/recall + 1/precision) 也就是一个调和平均式子
准确率(Accuracy):
acc = (TP+TN)/(TP+TN+FP+FN)
之所以要引入precision和recall就是因为当样本分布不均衡的时候acc的参考

意义不大，比如样本中99%都是负的只有1%是真的，当acc在训练集上很高的时

候，在实际测试集上很有可能偏向于FN。

RCU锁用原理非常简单，就是读的时候不需要加锁，写的时候需要加锁，这样加

快了读操作，所以适用于读操作很多的场景。原理就是写操作的时候要等宽限

期（grace period）过了才行,而且在修改的时候需要复制一份，修改之后替代

掉原来的。原理很简单，但是实现起来有点呵呵。反正暂时也用不着，等用到

了自然就学怎么用，也算是基本明白这玩意儿是干嘛的，为什么这么用的了。


